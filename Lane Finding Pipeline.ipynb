{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lane Finding Pipeline Homework\n",
    "***\n",
    "### Raw Lines - Result\n",
    "\n",
    "The bellow code shows the result of the raw lines\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=2):\n",
    "    \"\"\"\n",
    "    NOTE: this is the function you might want to use as a starting point once you want to \n",
    "    average/extrapolate the line segments you detect to map out the full\n",
    "    extent of the lane (going from the result shown in raw-lines-example.mp4\n",
    "    to that shown in P1_example.mp4).  \n",
    "    \n",
    "    Think about things like separating line segments by their \n",
    "    slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n",
    "    line vs. the right line.  Then, you can average the position of each of \n",
    "    the lines and extrapolate to the top and bottom of the lane.\n",
    "    \n",
    "    This function draws `lines` with `color` and `thickness`.    \n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    "    If you want to make the lines semi-transparent, think about combining\n",
    "    this function with the weighted_img() function below\n",
    "    \"\"\"\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((*img.shape, 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "# Python 3 has support for cool math symbols.\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "\n",
    "    gray = grayscale(image)\n",
    "\n",
    "    # Define a kernel size and apply Gaussian smoothing\n",
    "    kernel_size = 5\n",
    "    blur_gray = gaussian_blur(gray,kernel_size)\n",
    "\n",
    "    # Define our parameters for Canny and apply\n",
    "    low_threshold = 50\n",
    "    high_threshold = 150\n",
    "    edges = canny(blur_gray, low_threshold, high_threshold)\n",
    "\n",
    "    # Next we'll create a masked edges image using cv2.fillPoly()\n",
    "    mask = np.zeros_like(edges)   \n",
    "    ignore_mask_color = 255   \n",
    "\n",
    "    # This time we are defining a four sided polygon to mask\n",
    "    imshape = edges.shape\n",
    "    vertices = np.array([[(0,imshape[0]), (imshape[1]/2-50, imshape[0]/2+60), (imshape[1]/2+50, imshape[0]/2+60), (imshape[1],imshape[0])]], dtype=np.int32)\n",
    "    masked_edges = region_of_interest(edges, vertices)\n",
    "\n",
    "    # Define the Hough transform parameters\n",
    "    # Make a blank the same size as our image to draw on\n",
    "    rho = 1 # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi/180 # angular resolution in radians of the Hough grid\n",
    "    threshold = 3     # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_length = 15 #minimum number of pixels making up a line\n",
    "    max_line_gap = 3    # maximum gap in pixels between connectable line segments\n",
    "\n",
    "    # Run Hough on edge detected image\n",
    "    # Output \"lines\" is an array containing endpoints of detected line segments\n",
    "    lineimage = hough_lines(masked_edges, rho, theta, threshold, min_line_length, max_line_gap)\n",
    "\n",
    "    # Draw the lines on the edge image\n",
    "    lines_edges = weighted_img(lineimage, image, α=0.8, β=1., λ=0.)\n",
    "\n",
    "    return lines_edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video white.mp4\n",
      "[MoviePy] Writing video white.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:02<00:00, 89.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: white.mp4 \n",
      "\n",
      "CPU times: user 1.99 s, sys: 560 ms, total: 2.55 s\n",
      "Wall time: 2.86 s\n",
      "[MoviePy] >>>> Building video yellow.mp4\n",
      "[MoviePy] Writing video yellow.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 681/682 [00:08<00:00, 78.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: yellow.mp4 \n",
      "\n",
      "CPU times: user 7 s, sys: 1.69 s, total: 8.69 s\n",
      "Wall time: 9.1 s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'white.mp4'\n",
    "clip1 = VideoFileClip(\"solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n",
    "\n",
    "yellow_output = 'yellow.mp4'\n",
    "clip2 = VideoFileClip(\"solidYellowLeft.mp4\")\n",
    "yellow_clip = clip2.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"white.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"yellow.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solid Lines - Result\n",
    "***\n",
    "\n",
    "This is the result of solid lines\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    gray = grayscale(image)\n",
    "\n",
    "    # Define a kernel size and apply Gaussian smoothing\n",
    "    kernel_size = 5\n",
    "    blur_gray = gaussian_blur(gray,kernel_size)\n",
    "\n",
    "    # Define our parameters for Canny and apply\n",
    "    low_threshold = 50\n",
    "    high_threshold = 150\n",
    "    edges = canny(blur_gray, low_threshold, high_threshold)\n",
    "\n",
    "    # Next we'll create a masked edges image using cv2.fillPoly()\n",
    "    mask = np.zeros_like(edges)   \n",
    "    ignore_mask_color = 255   \n",
    "\n",
    "    # This time we are defining a four sided polygon to mask\n",
    "    imshape = edges.shape\n",
    "    vertices = np.array([[(0,imshape[0]), (imshape[1]/2-50, imshape[0]/2+60), (imshape[1]/2+50, imshape[0]/2+60), (imshape[1],imshape[0]-50)]], dtype=np.int32)\n",
    "    masked_edges = region_of_interest(edges, vertices)\n",
    "\n",
    "    # Define the Hough transform parameters\n",
    "    # Make a blank the same size as our image to draw on\n",
    "    rho = 1 # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi/180 # angular resolution in radians of the Hough grid\n",
    "    threshold = 3     # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_length = 15 #minimum number of pixels making up a line\n",
    "    max_line_gap = 3    # maximum gap in pixels between connectable line segments\n",
    "\n",
    "    # Run Hough on edge detected image\n",
    "    lines = cv2.HoughLinesP(masked_edges, rho, theta, threshold, np.array([]), minLineLength=min_line_length, maxLineGap=max_line_gap)\n",
    "\n",
    "    left_lines = []\n",
    "    right_lines = []\n",
    "    \n",
    "    left_slope = right_slope = 0\n",
    "    left_x = left_y = right_x = right_y = 0\n",
    "    \n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            #Find out the left line and the right line\n",
    "            if (x1 < imshape[1]/2 and x2 < imshape[1]/2):\n",
    "                left_lines.append(line)\n",
    "            elif (x1 > imshape[1]/2 and x2 > imshape[1]/2):\n",
    "                right_lines.append(line)\n",
    "    \n",
    "    \n",
    "    ##If the slope is too big or too small, it could be noise and we can remove it\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for line in left_lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            if ((abs((y2-y1)/(x2-x1)) > 0.2 and abs((y2-y1)/(x2-x1)) < 10)):\n",
    "                left_slope += (y2-y1)/(x2-x1)\n",
    "                left_x += x1 + x2\n",
    "                left_y += y1 + y2\n",
    "                i+=1\n",
    "                \n",
    "    for line in right_lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            if ((abs((y2-y1)/(x2-x1)) > 0.2 and abs((y2-y1)/(x2-x1)) < 10)): \n",
    "                right_slope += (y2-y1)/(x2-x1)\n",
    "                right_x += x1 + x2\n",
    "                right_y += y1 + y2\n",
    "                j+=1\n",
    "\n",
    "    #Or we can determine that it's not been detected\n",
    "    if i == 0:\n",
    "        return image\n",
    "    if j == 0:\n",
    "        return image\n",
    "    \n",
    "    #Average the left and right lines\n",
    "    left_slope = left_slope/i\n",
    "    right_slope = right_slope/j\n",
    "    \n",
    "    left_x = left_x/i/2\n",
    "    left_y = left_y/i/2\n",
    "    \n",
    "    right_x = right_x/j/2\n",
    "    right_y = right_y/j/2\n",
    "    \n",
    "    \n",
    "    \n",
    "    left_min_y = imshape[0]\n",
    "    left_min_x = int((left_min_y - left_y)/left_slope + left_x)\n",
    "    \n",
    "    left_max_y = imshape[0]/2+60\n",
    "    left_max_x = int((left_max_y - left_y)/left_slope + left_x)\n",
    "            \n",
    "        \n",
    "    right_min_y = imshape[0]\n",
    "    right_min_x = int((right_min_y - right_y)/right_slope + right_x)\n",
    "    \n",
    "    right_max_y = imshape[0]/2+60\n",
    "    right_max_x = int((right_max_y - right_y)/right_slope + right_x)\n",
    "    \n",
    "    #draw and merge lines\n",
    "    line_img = np.zeros((*masked_edges.shape, 3), dtype=np.uint8)\n",
    "    \n",
    "    cv2.line(line_img, (int(left_min_x), int(left_min_y)), (int(left_max_x), int(left_max_y)), color=[255, 0, 0], thickness=10)\n",
    "    cv2.line(line_img, (int(right_min_x), int(right_min_y)), (int(right_max_x), int(right_max_y)), color=[255, 0, 0], thickness=10)\n",
    "\n",
    "  \n",
    "    lines_edges = weighted_img(line_img, image, α=1, β=.5, λ=0.)\n",
    "\n",
    "\n",
    "    return lines_edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video white_solid.mp4\n",
      "[MoviePy] Writing video white_solid.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:02<00:00, 81.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: white_solid.mp4 \n",
      "\n",
      "CPU times: user 2.11 s, sys: 732 ms, total: 2.84 s\n",
      "Wall time: 3.13 s\n",
      "[MoviePy] >>>> Building video yellow_solid.mp4\n",
      "[MoviePy] Writing video yellow_solid.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 681/682 [00:09<00:00, 70.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: yellow_solid.mp4 \n",
      "\n",
      "CPU times: user 7.39 s, sys: 2.25 s, total: 9.64 s\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'white_solid.mp4'\n",
    "clip1 = VideoFileClip(\"solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n",
    "\n",
    "yellow_output = 'yellow_solid.mp4'\n",
    "clip2 = VideoFileClip(\"solidYellowLeft.mp4\")\n",
    "yellow_clip = clip2.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"white_solid.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"yellow_solid.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflect\n",
    "***\n",
    "\n",
    "The pipeline finding and filter algorithm is based on an assumption:\n",
    "\n",
    "* The slope of the pipeline should change constantly, the detected hough lines with large angle(nearly 90 degress) and small angle(almost 0 degrees) are noises and should be filterd.\n",
    "\n",
    "* The estimated pipeline is the average of those detected valid hough lines\n",
    "\n",
    "---\n",
    "Current algorithms are likely to cause it to fail under certain circumstances:\n",
    "\n",
    "1. The shape mask is assumed to be in the middle of the image, which may cause error when car change lines\n",
    "\n",
    "2. The shape mask also assumes a relatively level road, which makes it won't work when going downhill or uphill\n",
    "\n",
    "3. The parameters are hard coded, make it less adaptive, and would generate bad result under other lighting conditions(night, shadows, etc.)\n",
    "\n",
    "4. When front car change lines, the line detection will also generate bad result\n",
    "\n",
    "5. When the car is making turn, the lane-line may also hard to be detected\n",
    "\n",
    "---\n",
    "As a result, we can:\n",
    "1. Calculated the result also based on previous frames, which will make the filtering more robustic(Occlusion, shadows)\n",
    "\n",
    "2. Adaptively adjust the contrast and histogram of the image, normalize into certain light condition\n",
    "\n",
    "3. Detect the horizon and the road to adjust mask adaptively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional Challenge\n",
    "***\n",
    "\n",
    "We optimize the result by:\n",
    "\n",
    "1. Adjust the mask to fit this circumstance\n",
    "2. Increase contrase by applying histogram\n",
    "3. Remove all detected lines that almost horizontal or vertical\n",
    "3. Continue filter detected based on left and right lane-line slope\n",
    "\n",
    "---\n",
    "\n",
    "The result is shown bellow,\n",
    "\n",
    "Although we can see a draft detection result, it's still need to be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "\n",
    "    gray = grayscale(image)\n",
    "    \n",
    "    # Increase contrase\n",
    "    equ = cv2.equalizeHist(gray)\n",
    "    \n",
    "    # Define a kernel size and apply Gaussian smoothing\n",
    "    kernel_size = 7\n",
    "    blur_gray = gaussian_blur(equ,kernel_size)\n",
    "\n",
    "    # Define our parameters for Canny and apply\n",
    "    low_threshold = 50\n",
    "    high_threshold = 150\n",
    "    edges = canny(blur_gray, low_threshold, high_threshold)\n",
    "\n",
    "    # Next we'll create a masked edges image using cv2.fillPoly()\n",
    "    mask = np.zeros_like(edges)   \n",
    "    ignore_mask_color = 255   \n",
    "\n",
    "    # This time we are defining a four sided polygon to mask\n",
    "    imshape = edges.shape\n",
    "    vertices = np.array([[(0,imshape[0]-50), (imshape[1]/2-20, imshape[0]/2+100), (imshape[1]/2+20, imshape[0]/2+100), (imshape[1],imshape[0]-50)]], dtype=np.int32)\n",
    "    masked_edges = region_of_interest(edges, vertices)\n",
    "\n",
    "    # Define the Hough transform parameters\n",
    "    # Make a blank the same size as our image to draw on\n",
    "    rho = 1 # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi/180 # angular resolution in radians of the Hough grid\n",
    "    threshold = 3     # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_length = 15 #minimum number of pixels making up a line\n",
    "    max_line_gap = 3    # maximum gap in pixels between connectable line segments\n",
    "\n",
    "    # Run Hough on edge detected image\n",
    "    # Output \"lines\" is an array containing endpoints of detected line segments\n",
    "    \n",
    "    lines = cv2.HoughLinesP(masked_edges, rho, theta, threshold, np.array([]), minLineLength=min_line_length, maxLineGap=max_line_gap)\n",
    "    filtered_lines = []\n",
    "    \n",
    "    #Filter lines\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            \n",
    "            slope = ((y2-y1)/(x2-x1))\n",
    "            \n",
    "            if (abs(slope) > 0.3 and abs(slope) < 3):\n",
    "                if (x1 < imshape[1]/2 and x2 < imshape[1]/2 and slope < 0):\n",
    "                    filtered_lines.append(line)\n",
    "                elif (x1 > imshape[1]/2 and x2 > imshape[1]/2 and slope > 0):\n",
    "                    filtered_lines.append(line)\n",
    "\n",
    "                    \n",
    "    line_img = np.zeros((*masked_edges.shape, 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, filtered_lines)\n",
    "\n",
    "    # Draw the lines on the edge image\n",
    "    lines_edges = weighted_img(line_img, image, α=0.8, β=1., λ=0.)\n",
    "\n",
    "    return lines_edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video extra.mp4\n",
      "[MoviePy] Writing video extra.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [00:06<00:00, 35.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: extra.mp4 \n",
      "\n",
      "CPU times: user 5.04 s, sys: 1.97 s, total: 7.01 s\n",
      "Wall time: 7.77 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"extra.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "white_output = 'extra.mp4'\n",
    "clip1 = VideoFileClip(\"challenge.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    gray = grayscale(image)\n",
    "    equ = cv2.equalizeHist(gray)\n",
    "    # Define a kernel size and apply Gaussian smoothing\n",
    "    kernel_size = 7\n",
    "    blur_gray = gaussian_blur(equ,kernel_size)\n",
    "\n",
    "    # Define our parameters for Canny and apply\n",
    "    low_threshold = 30\n",
    "    high_threshold = 100\n",
    "    edges = canny(blur_gray, low_threshold, high_threshold)\n",
    "\n",
    "    # Next we'll create a masked edges image using cv2.fillPoly()\n",
    "    mask = np.zeros_like(edges)   \n",
    "    ignore_mask_color = 255   \n",
    "\n",
    "    # This time we are defining a four sided polygon to mask\n",
    "    imshape = edges.shape\n",
    "    vertices = np.array([[(0,imshape[0]-50), (imshape[1]/2-20, imshape[0]/2+100), (imshape[1]/2+20, imshape[0]/2+100), (imshape[1],imshape[0]-50)]], dtype=np.int32)\n",
    "    masked_edges = region_of_interest(edges, vertices)\n",
    "    # Define the Hough transform parameters\n",
    "    # Make a blank the same size as our image to draw on\n",
    "    rho = 1 # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi/180 # angular resolution in radians of the Hough grid\n",
    "    threshold = 3     # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_length = 15 #minimum number of pixels making up a line\n",
    "    max_line_gap = 3    # maximum gap in pixels between connectable line segments\n",
    "\n",
    "    # Run Hough on edge detected image\n",
    "    lines = cv2.HoughLinesP(masked_edges, rho, theta, threshold, np.array([]), minLineLength=min_line_length, maxLineGap=max_line_gap)\n",
    "\n",
    "    \n",
    "    #Filter lines\n",
    "    \n",
    "    filtered_lines = []\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            \n",
    "            slope = ((y2-y1)/(x2-x1))\n",
    "            \n",
    "            if (abs(slope) > 0.3 and abs(slope) < 3):\n",
    "                if (x1 < imshape[1]/2 and x2 < imshape[1]/2 and slope < 0):\n",
    "                    filtered_lines.append(line)\n",
    "                elif (x1 > imshape[1]/2 and x2 > imshape[1]/2 and slope > 0):\n",
    "                    filtered_lines.append(line)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    left_lines = []\n",
    "    right_lines = []\n",
    "    \n",
    "    left_slope = right_slope = 0\n",
    "    left_x = left_y = right_x = right_y = 0\n",
    "    \n",
    "    for line in filtered_lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            #Find out the left line and the right line\n",
    "            if (x1 < imshape[1]/2 and x2 < imshape[1]/2):\n",
    "                left_lines.append(line)\n",
    "            elif (x1 > imshape[1]/2 and x2 > imshape[1]/2):\n",
    "                right_lines.append(line)\n",
    "    \n",
    "    \n",
    "    ##If the slope is too big or too small, it could be noise and we can remove it\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for line in left_lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            if ((abs((y2-y1)/(x2-x1)) > 0.3 and abs((y2-y1)/(x2-x1)) < 3)):\n",
    "                left_slope += (y2-y1)/(x2-x1)\n",
    "                left_x += x1 + x2\n",
    "                left_y += y1 + y2\n",
    "                i+=1\n",
    "                \n",
    "    for line in right_lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            if ((abs((y2-y1)/(x2-x1)) > 0.3 and abs((y2-y1)/(x2-x1)) < 3)): \n",
    "                right_slope += (y2-y1)/(x2-x1)\n",
    "                right_x += x1 + x2\n",
    "                right_y += y1 + y2\n",
    "                j+=1\n",
    "\n",
    "    #Or we can determine that it's not been detected\n",
    "    if i == 0 or left_slope == 0:\n",
    "        return image\n",
    "    if j == 0 or right_slope == 0:\n",
    "        return image\n",
    "    \n",
    "    #Average the left and right lines\n",
    "    left_slope = left_slope/i\n",
    "    right_slope = right_slope/j\n",
    "    \n",
    "    left_x = left_x/i/2\n",
    "    left_y = left_y/i/2\n",
    "    \n",
    "    right_x = right_x/j/2\n",
    "    right_y = right_y/j/2\n",
    "    \n",
    "    \n",
    "    \n",
    "    left_min_y = imshape[0]\n",
    "    left_min_x = int((left_min_y - left_y)/left_slope + left_x)\n",
    "    \n",
    "    left_max_y = imshape[0]/2+60\n",
    "    left_max_x = int((left_max_y - left_y)/left_slope + left_x)\n",
    "            \n",
    "        \n",
    "    right_min_y = imshape[0]\n",
    "    right_min_x = int((right_min_y - right_y)/right_slope + right_x)\n",
    "    \n",
    "    right_max_y = imshape[0]/2+60\n",
    "    right_max_x = int((right_max_y - right_y)/right_slope + right_x)\n",
    "    \n",
    "    #draw and merge lines\n",
    "    line_img = np.zeros((*masked_edges.shape, 3), dtype=np.uint8)\n",
    "    \n",
    "    cv2.line(line_img, (int(left_min_x), int(left_min_y)), (int(left_max_x), int(left_max_y)), color=[255, 0, 0], thickness=10)\n",
    "    cv2.line(line_img, (int(right_min_x), int(right_min_y)), (int(right_max_x), int(right_max_y)), color=[255, 0, 0], thickness=10)\n",
    "\n",
    "  \n",
    "    lines_edges = weighted_img(line_img, image, α=1, β=.5, λ=0.)\n",
    "\n",
    "\n",
    "    return lines_edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video extra_solid.mp4\n",
      "[MoviePy] Writing video extra_solid.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [00:07<00:00, 33.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: extra_solid.mp4 \n",
      "\n",
      "CPU times: user 5.87 s, sys: 2.11 s, total: 7.98 s\n",
      "Wall time: 8.34 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"extra_solid.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "white_output = 'extra_solid.mp4'\n",
    "clip1 = VideoFileClip(\"challenge.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
